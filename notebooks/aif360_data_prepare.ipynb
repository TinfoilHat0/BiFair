{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "import my_utils as ut\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset, BankDataset\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions \\\n",
    "#     import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    }
   ],
   "source": [
    "if data == 'adult':\n",
    "    protect_attr= 'sex'\n",
    "    label = 'income-per-year'\n",
    "    ds = AdultDataset()\n",
    "    \n",
    "elif data == 'medical':\n",
    "    protect_attr='RACE'\n",
    "    label='UTILIZATION'\n",
    "    ds = MEPSDataset19()\n",
    "\n",
    "elif data == 'compas':\n",
    "    protect_attr= 'race'\n",
    "    label = 'two_year_recid'\n",
    "    ds = CompasDataset()\n",
    "    # make 1 the favorable label for consistency\n",
    "    ds.labels = np.abs(1-ds.labels) \n",
    "\n",
    "elif data == 'bank':\n",
    "    protect_attr = 'age'\n",
    "    label = 'y'\n",
    "    ds = BankDataset()\n",
    "    \n",
    "elif data == 'german':\n",
    "    protect_attr = 'sex'\n",
    "    label = 'credit'\n",
    "    ds = GermanDataset()\n",
    "    # make 0 the unfavorable label for consistency\n",
    "    ds.labels[ds.labels == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds, tmp_ds = ds.split([0.6], shuffle=True)\n",
    "v_ds, te_ds = tmp_ds.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = tr_ds.convert_to_dataframe()[0]\n",
    "df_v = v_ds.convert_to_dataframe()[0]\n",
    "df_te = te_ds.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_stats(df, protect_attr='sex', label='income-per-year'):\n",
    "    protect_ratio = df[protect_attr].value_counts(normalize=True)\n",
    "    label_ratio = df[label].value_counts(normalize=True)\n",
    "    return protect_ratio, label_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.971682\n",
       "0.0    0.028318\n",
       "Name: age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.874863\n",
       "1.0    0.125137\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "protect_ratio, label_ratio = get_ds_stats(df_tr, protect_attr, label)\n",
    "display(protect_ratio, label_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0254, 0.9965, 0.5402, 1.1386])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.11857642685326919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8531051825934834"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0065602449158101905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.02175814563743713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_exp_p_fav = protect_ratio[1]*label_ratio[1]\n",
    "pr_obs_p_fav = df_tr[(df_tr[protect_attr]==1) & (df_tr[label]==1)].shape[0]/df_tr.shape[0]\n",
    "w_p_fav = pr_exp_p_fav/pr_obs_p_fav\n",
    "\n",
    "pr_exp_p_unfav = protect_ratio[1]*label_ratio[0]\n",
    "pr_obs_p_unfav = df_tr[(df_tr[protect_attr]==1) & (df_tr[label]==0)].shape[0]/df_tr.shape[0]\n",
    "w_p_unfav = pr_exp_p_unfav/pr_obs_p_unfav\n",
    "\n",
    "pr_exp_up_fav = protect_ratio[0]*label_ratio[1]\n",
    "pr_obs_up_fav = df_tr[(df_tr[protect_attr]==0) & (df_tr[label]==1)].shape[0]/df_tr.shape[0]\n",
    "w_up_fav = pr_exp_up_fav/pr_obs_up_fav\n",
    "\n",
    "pr_exp_up_unfav = protect_ratio[0]*label_ratio[0]\n",
    "pr_obs_up_unfav = df_tr[(df_tr[protect_attr]==0) & (df_tr[label]==0)].shape[0]/df_tr.shape[0]\n",
    "w_up_unfav = pr_exp_up_unfav/pr_obs_up_unfav\n",
    "\n",
    "kamiran_weights = torch.tensor([w_p_fav, w_p_unfav, w_up_fav, w_up_unfav]).float()\n",
    "display(kamiran_weights)\n",
    "display(pr_obs_p_fav, pr_obs_p_unfav, pr_obs_up_fav, pr_obs_up_unfav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12203218183864072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.23166023166023167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8779678181613593"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7683397683397684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_fav_given_p = pr_obs_p_fav/protect_ratio[1.0]\n",
    "pr_fav_given_up = pr_obs_up_fav/protect_ratio[0.0]\n",
    "pr_unfav_given_p = pr_obs_p_unfav/protect_ratio[1.0]\n",
    "pr_unfav_given_up = pr_obs_up_unfav/protect_ratio[0.0]\n",
    "\n",
    "display(pr_fav_given_p, pr_fav_given_up, pr_unfav_given_p, pr_unfav_given_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_torch(df, protect_attr='sex', label='income-per-year'):\n",
    "    meta = df[protect_attr].values\n",
    "    \n",
    "    df.drop(columns=[protect_attr], inplace=True) # dropping demographics from the dataset\n",
    "    X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values, \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    print(meta.shape, X.shape, y.shape)\n",
    "    X = torch.tensor(X).float()\n",
    "    y = torch.tensor(y).float()\n",
    "    meta = torch.tensor(meta).float()\n",
    "    torch_ds = ut.DatasetWithMeta(X, y, meta)\n",
    "    return torch_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18292,) (18292, 56) (18292,)\n",
      "(6098,) (6098, 56) (6098,)\n",
      "(6098,) (6098, 56) (6098,)\n"
     ]
    }
   ],
   "source": [
    "torch_tr_ds = convert_df_to_torch(df_tr, protect_attr, label)\n",
    "torch_v_ds = convert_df_to_torch(df_v, protect_attr, label)\n",
    "torch_te_ds = convert_df_to_torch(df_te, protect_attr, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(torch_tr_ds, f'../data/{data}_pytorch/{data}_train.pt')\n",
    "# torch.save(torch_v_ds, f'../data/{data}_pytorch/{data}_val.pt')\n",
    "# torch.save(torch_te_ds, f'../data/{data}_pytorch/{data}_test.pt')\n",
    "# torch.save(kamiran_weights, f'../data/{data}_pytorch/kamiran_weights_{data}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda2893f7c78e4248a9bda8fc39f732a94d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
